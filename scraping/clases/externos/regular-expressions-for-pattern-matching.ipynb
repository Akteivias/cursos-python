{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are they bots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"https://assets.datacamp.com/production/repositories/4510/datasets/19e319827a9c77db36702cf59bf61b1ef039de43/short_tweets.csv\",\n",
    "                      \t\t\t header=0,\n",
    "                                 names = [\"target\", \"id\", \"date\", \"flag\", \"user\", \"text\"])\n",
    "sentiment_analysis = dataset[\"text\"].iloc[105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the re module\n",
    "import re\n",
    "\n",
    "# Write the regex\n",
    "regex = r\"@robot\\d\\W\"\n",
    "\n",
    "# Find all matches of regex\n",
    "print(re.findall(regex, sentiment_analysis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The company that you are working for asked you to perform a sentiment analysis using a dataset with tweets. First of all, you need to do some cleaning and extract some information.<br>\n",
    "While printing out some text, you realize that some tweets contain user mentions. Some of these mentions follow a very strange pattern. A few examples that you notice: <code>@robot3!</code>, <code>@robot5&amp;</code> and <code>@robot7#</code></p>\n",
    "<p>To analyze if those users are bots, you will do a proof of concept with one tweet and extract them using the <code>.findall()</code> method. </p>\n",
    "<p>You write down some helpful metacharacters to help you later:</p>\n",
    "<p><code>\\d</code>: digit<br>\n",
    "<code>\\w</code>: word character<br>\n",
    "<code>\\W</code>: non-word character<br>\n",
    "<code>\\s</code>: whitespace</p>\n",
    "<p>The text of one tweet was saved in the variable <code>sentiment_analysis</code>. You can use <code>print(sentiment_analysis)</code> to view it in the IPython Shell.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Import the <code>re</code> module.</li>\n",
    "<li>Write a regex that matches the user mentions that follows the pattern, e.g. <code>@robot3!</code>. </li>\n",
    "<li>Find all the matches of the pattern in the <code>sentiment_analysis</code> variable.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>To import <code>module</code>, use <code>import module</code>.</li>\n",
    "<li>Always start a regex with <code>r</code>. Remember that normal characters match themselves. Use <code>\\d</code> to indicate digits and <code>\\W</code> to indicate any non-word character, for example, <code>&amp;</code> or <code>#</code>.</li>\n",
    "<li>To find all matches of <code>pattern</code> in a <code>string</code>, use the method <code>.findall()</code> from the <code>re</code> module. Don't forget to specify the <code>pattern</code> and the <code>string</code> as arguments.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "dataset = pd.read_csv(\"https://assets.datacamp.com/production/repositories/4510/datasets/19e319827a9c77db36702cf59bf61b1ef039de43/short_tweets.csv\", \n",
    "                                 header= 0,\n",
    "                                 names = [\"target\", \"id\", \"date\", \"flag\", \"user\", \"text\"])\n",
    "sentiment_analysis = dataset[\"text\"].iloc[653]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>While examining the tweet text in your dataset, you detect that some tweets carry more information. The text contains the number of retweets, user mentions, and likes. You decide to extract this important information that is given as in this example:  </p>\n",
    "<p><code>Agh,snow! User_mentions:9, likes: 5, number of retweets: 4</code> </p>\n",
    "<p>You pull a list of metacharacters:<code>\\d</code> digit,<code>\\w</code> word character,<code>\\s</code> whitespace. </p>\n",
    "<p>Always indicate whitespace with metacharacters.</p>\n",
    "<p>The variable <code>sentiment_analysis</code> containing the text of one tweet and the <code>re</code> module were loaded in your session. You can use <code>print()</code> to view it in the IPython Shell.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "dataset = pd.read_csv(\"https://assets.datacamp.com/production/repositories/4510/datasets/19e319827a9c77db36702cf59bf61b1ef039de43/short_tweets.csv\", \n",
    "                                 header= 0,\n",
    "                                 names = [\"target\", \"id\", \"date\", \"flag\", \"user\", \"text\"])\n",
    "sentiment_analysis = dataset[\"text\"].iloc[763]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Some of the tweets in your dataset were downloaded incorrectly. Instead of having spaces to separate words, they have strange characters. You decide to use regular expressions to handle this situation. You print some of these tweets to understand which pattern you need to match.  </p>\n",
    "<p>You notice that the <em>sentences</em> are always separated by a special character, followed by a number, the word <code>break</code>, and after that, another special character, e.g <strong><code>&amp;4break!</code></strong>. The <em>words</em> are always separated by a special character, the word <code>new</code>, and a normal random character, e.g <strong><code>#newH</code></strong>.</p>\n",
    "<p>The variable <code>sentiment_analysis</code> containing the text of one tweet, as well as the <code>re</code> module were already loaded in your session. You can use <code>print(sentiment_analysis)</code> to view it in the IPython Shell.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Everything clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"https://assets.datacamp.com/production/repositories/4510/datasets/19e319827a9c77db36702cf59bf61b1ef039de43/short_tweets.csv\", \n",
    "                                 header= 0,\n",
    "                                 names = [\"target\", \"id\", \"date\", \"flag\", \"user\", \"text\"])\n",
    "sentiment_analysis = dataset[\"text\"].iloc[545:548]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import re module\n",
    "import re\n",
    "\n",
    "for tweet in sentiment_analysis:\n",
    "  \t# Write regex to match http links and print out result\n",
    "\tprint(re.findall(r\"http\\S+\", tweet))\n",
    "\n",
    "\t# Write regex to match user mentions and print out result\n",
    "\tprint(re.findall(r\"@\\w+\", tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Back to your Twitter sentiment analysis project! There are several types of strings that increase your sentiment analysis complexity. But these strings do not provide any useful sentiment. Among them, we can have links and user mentions.  </p>\n",
    "<p>In order to clean the tweets, you want to extract some examples first. You know that most of the times links start with <code>http</code> and do not contain any whitespace, e.g. <code>https://www.datacamp.com</code>. User mentions start with <code>@</code> and can have letters and numbers only, e.g. <code>@johnsmith3</code>.</p>\n",
    "<p>You write down some helpful quantifiers to help you: <code>*</code> zero or more times, <code>+</code> once or more, <code>?</code> zero or once.</p>\n",
    "<p>The list <code>sentiment_analysis</code> containing the text of three tweet are already loaded in your session. You can use <code>print()</code> to view the data in the IPython Shell.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Import the <code>re</code> module.</li>\n",
    "<li>Write a regex to find all the matches of <code>http</code> links appearing in each <code>tweet</code> in <code>sentiment_analysis</code>. Print out the result.</li>\n",
    "<li>Write a regex to find all the matches of user mentions appearing in each <code>tweet</code> in  <code>sentiment_analysis</code>. Print out the result.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>To import <code>module</code>, use <code>import module</code>.</li>\n",
    "<li>To match a pattern that starts with <code>sequence</code> and has no whitespace, use <code>sequence</code> and <code>\\S+</code>. To find all matches, use the method <code>.findall()</code>.</li>\n",
    "<li>To match a pattern that starts with <code>@</code> symbol and can contain letters and numbers, use <code>@</code> and <code>\\w+</code>. To find all matches, use the method <code>.findall()</code>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some time ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"https://assets.datacamp.com/production/repositories/4510/datasets/19e319827a9c77db36702cf59bf61b1ef039de43/short_tweets.csv\", \n",
    "                                 header= 0,\n",
    "                                 names = [\"target\", \"id\", \"date\", \"flag\", \"user\", \"text\"])\n",
    "sentiment_analysis = dataset[\"text\"].iloc[232:235]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>You are interested in knowing when the tweets were posted. After reading a little bit more, you learn that dates are provided in different ways. You decide to extract the dates using <code>.findall()</code> so you can normalize them afterwards to make them all look the same.  </p>\n",
    "<p>You realize that the dates are always presented in one of the following ways:</p>\n",
    "<p><code>27 minutes ago</code></p>\n",
    "<p><code>4 hours ago</code></p>\n",
    "<p><code>23rd june 2018</code></p>\n",
    "<p><code>1st september 2019 17:25</code></p>\n",
    "<p>The list <code>sentiment_analysis</code> containing the text of three tweets, as well as the <code>re</code> module are already loaded in your session. You can use <code>print()</code> to view the data in the IPython Shell.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"https://assets.datacamp.com/production/repositories/4510/datasets/19e319827a9c77db36702cf59bf61b1ef039de43/short_tweets.csv\", \n",
    "                                 header= 0,\n",
    "                                 names = [\"target\", \"id\", \"date\", \"flag\", \"user\", \"text\"])\n",
    "sentiment_analysis = dataset[\"text\"].iloc[365]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Your next step is to tokenize the text of your tweets. Tokenization is the process of breaking a string into lexical units or, in simpler terms, words. But first, you need to remove hashtags so they do not cloud your process. You realize that hashtags start with a <code>#</code> symbol and contain letters and numbers but never whitespace. After that, you plan to split the text at whitespace matches to get the tokens.</p>\n",
    "<p>You bring your list of quantifiers to help you: <code>*</code> zero o more times, <code>+</code> once or more, <code>?</code> zero or once, <code>{n, m}</code> minimum n, maximum m.</p>\n",
    "<p>The variable <code>sentiment_analysis</code> containing the text of one tweet as well as the <code>re</code> module are already loaded in your session. You can use <code>print(sentiment_analysis)</code> to view it in the IPython Shell.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"https://assets.datacamp.com/production/repositories/4510/datasets/19e319827a9c77db36702cf59bf61b1ef039de43/short_tweets.csv\", \n",
    "                                 header= 0,\n",
    "                                 names = [\"target\", \"id\", \"date\", \"flag\", \"user\", \"text\"])\n",
    "sentiment_analysis = dataset[\"text\"].iloc[780:782]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a regex to match text file name\n",
    "regex = r\"^[aeiouAEIOU]{2,3}.+txt\"\n",
    "\n",
    "for text in sentiment_analysis:\n",
    "\t# Find all matches of the regex\n",
    "\tprint(re.findall(regex, text))\n",
    "    \n",
    "\t# Replace all matches with empty string\n",
    "\tprint(re.sub(regex, \"\", text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>You are not satisfied with your tweets dataset cleaning. There are still extra strings that do not provide any sentiment. Among them are strings that refer to text file names.  </p>\n",
    "<p>You also find a way to detect them:</p>\n",
    "<ul>\n",
    "<li>They appear at the start of the string.</li>\n",
    "<li>They always start with a sequence of 2 or 3 upper or lowercase vowels (a e i o u). </li>\n",
    "<li>They always finish with the <code>txt</code> ending. </li>\n",
    "</ul>\n",
    "<p>You are not sure if you should remove them directly. So you write a script to find and store them in a separate dataset.   </p>\n",
    "<p>You write down some metacharacters to help you: <code>^</code> anchor to beginning, <code>.</code> any character.</p>\n",
    "<p>The variable <code>sentiment_analysis</code> containing the text of two tweets as well as the <code>re</code> module are already loaded in your session. You can use <code>print()</code> to view it in the IPython Shell.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Write a regex that matches the pattern of the text file names, e.g. <code>aemyfile.txt</code>.</li>\n",
    "<li>Find all matches of the regex in the elements of <code>sentiment_analysis</code>. Print out the result.</li>\n",
    "<li>Replace all matches of the regex with an empty string <code>\"\"</code>. Print out the result.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Use <code>[]</code> to indicate optional characters such as <code>[aeiou]</code>. The dot <code>.</code> metacharacter matches any character. The <code>txt</code> ending can match itself. Use <code>^</code> to anchor it to the beginning of the string.</li>\n",
    "<li>Use <code>.findall()</code> to find all matches of a regex. Specify <code>regex</code> and <code>string</code>.</li>\n",
    "<li>Use <code>.sub()</code> to replace all matches of a regex. Specify the <code>regex</code>, <code>new</code> sequence, and <code>string</code>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Give me your email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "emails = [\"n.john.smith@gmail.com\", \"87victory@hotmail.com\", \"!#mary-=@msca.net\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a regex to match a valid email address\n",
    "regex = r\"[A-Za-z0-9!#%&*\\$\\.]+@\\w+\\.com\"\n",
    "\n",
    "for example in emails:\n",
    "  \t# Match the regex to the string\n",
    "    if re.match(regex, example):\n",
    "        # Complete the format method to print out the result\n",
    "      \tprint(\"The email {email_example} is a valid email\".format(email_example=example))\n",
    "    else:\n",
    "      \tprint(\"The email {email_example} is invalid\".format(email_example=example))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>A colleague has asked for your help! When a user signs up on the company website, they must provide a valid email address.<br>\n",
    "The company puts some rules in place to verify that the given email address is valid:</p>\n",
    "<ul>\n",
    "<li>The first part can contain:<ul>\n",
    "<li>Upper <code>A-Z</code> and lowercase letters <code>a-z</code></li>\n",
    "<li>Numbers</li>\n",
    "<li>Characters: <code>!</code>, <code>#</code>, <code>%</code>, <code>&amp;</code>, <code>*</code>, <code>$</code>, <code>.</code></li></ul></li>\n",
    "<li>Must have <code>@</code></li>\n",
    "<li>Domain:<ul>\n",
    "<li>Can contain any word characters</li>\n",
    "<li>But only <code>.com</code> ending is allowed</li></ul></li>\n",
    "</ul>\n",
    "<p>The project consist of writing a script that checks if the email address follow the correct pattern. Your colleague gave you a list of email addresses as examples to test.</p>\n",
    "<p>The list <code>emails</code> as well as the <code>re</code> module are loaded in your session. You can use <code>print(emails)</code> to view the emails in the IPython Shell.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Write a regular expression to match valid email addresses as described.</li>\n",
    "<li>Match the regex to the elements contained in <code>emails</code>.</li>\n",
    "<li>To print out the message indicating if it is a valid email or not, complete <code>.format()</code> statement.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>To choose between different characters use <code>[]</code>. Use <code>a-z</code> for lowercase, <code>A-Z</code> for uppercase letters and <code>0-9</code> for numbers. Don't forget to escape <code>.</code> and <code>$</code> as they have another meaning. Use <code>\\w</code> for any word character.</li>\n",
    "<li>To match a <code>pattern</code> to a <code>string</code>, use <code>.match(pattern, string)</code>.</li>\n",
    "<li>Remember the <code>.format()</code> syntax: <code>\"text {variable}\".format(variable=string)</code>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invalid password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "passwords = [\"Apple34!rose\", \"My87hou#4$\", \"abc123\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a regex to match a valid password\n",
    "regex = r\"[A-Za-z0-9!#%&*\\$\\.]{8,20}\" \n",
    "\n",
    "for example in passwords:\n",
    "  \t# Scan the strings to find a match\n",
    "    if re.search(regex, example):\n",
    "        # Complete the format method to print out the result\n",
    "      \tprint(\"The password {pass_example} is a valid password\".format(pass_example=example))\n",
    "    else:\n",
    "      \tprint(\"The password {pass_example} is invalid\".format(pass_example=example))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The second part of the website project is to write a script that validates the password entered by the user. \n",
    "The company also puts some rules in order to verify valid passwords:</p>\n",
    "<ul>\n",
    "<li>It can contain lowercase <code>a-z</code> and uppercase letters <code>A-Z</code> </li>\n",
    "<li>It can contain numbers</li>\n",
    "<li>It can contain the symbols: <code>*</code>, <code>#</code>, <code>$</code>, <code>%</code>, <code>!</code>, <code>&amp;</code>, <code>.</code> </li>\n",
    "<li>It must be at least 8 characters long but not more than 20</li>\n",
    "</ul>\n",
    "<p>Your colleague also gave you a list of passwords as examples to test.</p>\n",
    "<p>The list <code>passwords</code> and the module <code>re</code> are loaded in your session. You can use <code>print(passwords)</code> to view them in the IPython Shell.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Write a regular expression to match valid passwords as described.</li>\n",
    "<li>Scan the elements in the <code>passwords</code> list to find out if they are valid passwords.</li>\n",
    "<li>To print out the message indicating if it is a valid password or not, complete <code>.format()</code> statement.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>To choose between different characters use <code>[]</code>. Use <code>a-z</code> for lowercase,<code>A-Z</code> for uppercase letters and <code>0-9</code> for numbers. Don't forget to escape <code>.</code> and <code>$</code>. Use the <code>{n, m}</code> quantifier to specify minimum <code>n</code> and maximum <code>m</code> repetitions.</li>\n",
    "<li>To scan the <code>string</code>, use <code>.search()</code> method.</li>\n",
    "<li>Remember the <code>.format()</code> syntax: <code>\"text {variable}\".format(variable=string)</code>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "string = \"I want to see that <strong>amazing show</strong> again!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import re\n",
    "import re\n",
    "\n",
    "# Write a regex to eliminate tags\n",
    "string_notags = re.sub(r\"<.+?>\", \"\", string)\n",
    "\n",
    "# Print out the result\n",
    "print(string_notags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>You need to keep working and cleaning your tweets dataset. You realize that there are some HTML tags present. You need to remove them but keep the inside content as they are useful for analysis.     </p>\n",
    "<p>Let's take a look at this sentence containing an HTML tag:  </p>\n",
    "<p><code>I want to see that &lt;strong&gt;amazing show&lt;/strong&gt; again!</code>.   </p>\n",
    "<p>You know that for getting HTML tag you need to match anything that sits inside angle brackets <code>&lt;</code> <code>&gt;</code>. But the biggest problem is that the closing tag has the same structure. If you match too much, you will end up removing key information. So you need to decide whether to use a greedy or a lazy quantifier. </p>\n",
    "<p>The string is already loaded as <code>string</code> to your session.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Import the <code>re</code> module.</li>\n",
    "<li>Write a <code>regex</code> expression to replace <strong>HTML tags</strong> with an empty string.</li>\n",
    "<li>Print out the result.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Write a regex that looks for any character one or more times but uses a lazy quantifier by appending <code>?</code>. Use it inside the function <code>re.sub(regex,replacement, string)</code>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "dataset = pd.read_csv(\"https://assets.datacamp.com/production/repositories/4510/datasets/19e319827a9c77db36702cf59bf61b1ef039de43/short_tweets.csv\", \n",
    "                                 header= 0,\n",
    "                                 names = [\"target\", \"id\", \"date\", \"flag\", \"user\", \"text\"])\n",
    "sentiment_analysis = dataset[\"text\"].iloc[91]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Next, you see that numbers still appear in the text of the tweets. So, you decide to find all of them.  </p>\n",
    "<p>Let's imagine that you want to extract the number contained in the sentence <code>I was born on April 24th</code>. A lazy quantifier will make the regex return <code>2</code> and <code>4</code>, because they will match as few characters as needed. However, a greedy quantifier will return the entire <code>24</code> due to its need to match as much as possible.</p>\n",
    "<p>The <code>re</code> module as well as the variable <code>sentiment_analysis</code> are already loaded in your session. You can use <code>print(sentiment_analysis)</code> to view it in the IPython Shell.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "dataset = pd.read_csv(\"https://assets.datacamp.com/production/repositories/4510/datasets/19e319827a9c77db36702cf59bf61b1ef039de43/short_tweets.csv\", \n",
    "                                 header= 0,\n",
    "                                 names = [\"target\", \"id\", \"date\", \"flag\", \"user\", \"text\"])\n",
    "sentiment_analysis = dataset[\"text\"].iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>You have done some cleaning in your dataset but you are worried that there are sentences encased in parentheses that may cloud your analysis.  </p>\n",
    "<p>Again, a greedy or a lazy quantifier may lead to different results.   </p>\n",
    "<p>For example, if you want to extract a word starting with <code>a</code> and ending with <code>e</code> in the string <code>I like apple pie</code>, you may think that applying the greedy regex <code>a.+e</code> will return <code>apple</code>. However, your match will be <code>apple pie</code>. A way to overcome this is to make it lazy by using <code>?</code> which will return <code>apple</code>.</p>\n",
    "<p>The <code>re</code> module and the variable <code>sentiment_analysis</code> are already loaded in your session.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
